<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/c4250770ab8708b6-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/f7db1e3b5f03d91f-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/bd9e0cabbc41a073.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/2799974cb986be26.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-471744ee643a0223.js"/><script src="/_next/static/chunks/4bd1b696-0f420227e77e2ac1.js" async=""></script><script src="/_next/static/chunks/517-974876eb33736c9f.js" async=""></script><script src="/_next/static/chunks/main-app-f6af5caa5fb68cd4.js" async=""></script><script src="/_next/static/chunks/795d4814-4cf137b2b18c6ba6.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-37a392b9a35a4a16.js" async=""></script><script src="/_next/static/chunks/f7333993-1ff95e909beea13f.js" async=""></script><script src="/_next/static/chunks/910-a97ce0c10fadb44e.js" async=""></script><script src="/_next/static/chunks/app/academic/page-22f8083129f4684b.js" async=""></script><meta name="next-size-adjust"/><title>Yinan Zhou</title><meta name="description" content="Personal Website"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_48ea4f"><main class="flex min-h-screen flex-col bg-neutral-100 dark:bg-neutral-900"><nav class="fixed mx-auto font-bold top-0 left-0 right-0 z-10 bg-neutral-100 dark:bg-neutral-900 bg-opacity-100 border border-neutral-300  border-l-transparent border-r-transparent border-t-transparent dark:border-[#33353F] dark:border-l-transparent dark:border-r-transparent dark:border-t-transparent"><div class="flex container lg:py-4 items-center justify-between mx-auto px-4 py-2"><div class="mobile-menu block md:hidden"><button class="flex items-center px-3 py-2 border rounded text-neutral-600 hover:text-neutral-500 dark:text-neutral-300 hover:dark:text-neutral-200 "><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" aria-hidden="true" class="h-5 w-5" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg></button></div><div class="menu hidden md:block md:w-auto" id="navbar"><ul class="flex p-4 md:p-0 md:flex-row md:space-x-8 mt-0"><li><div class="relative inline-block"><a class="txt-color-primary block relative hover:scale-110" href="/work">Work<div class="absolute -bottom-0.5 left-0 h-0.5 gradient-bg" style="width:0px"></div></a></div></li><li><div class="relative inline-block"><a class="txt-color-primary block relative hover:scale-110" href="/projects">Projects<div class="absolute -bottom-0.5 left-0 h-0.5 gradient-bg" style="width:0px"></div></a></div></li><li><div class="relative inline-block"><a class="text-primary-600 dark:text-primary-400 block relative hover:scale-110" href="/academic">Academic<div class="absolute -bottom-0.5 left-0 h-0.5 gradient-bg" style="width:0px"></div></a></div></li></ul></div><a class="text-2xl md:text-5xl text-neutral-900 dark:text-neutral-100 hover:scale-110 __className_64bce7" href="/">YINAN</a><div class="menu hidden md:block md:w-auto" id="navbar"><div class="socials flex p-4 md:p-0 md:flex-row md:space-x-8 space-x-4 mt-0 justify-items-end"><a target="_blank" class="content-center group" href="https://github.com/yinanazhou"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="txt-color-primary group-hover:scale-110 transition-transform" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a target="_blank" class="content-center group" href="https://www.linkedin.com/in/yinan-zhou-ana/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="txt-color-primary group-hover:scale-110 transition-transform" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><button class="text-sm border rounded-full px-2 w-8 h-8 place-items-center bg-neutral-800 hover:bg-neutral-800 text-neutral-100 dark:bg-neutral-200 dark:hover:bg-neutral-200 dark:text-neutral-900 hover:scale-110 transition-transform"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 3a9 9 0 1 0 9 9c0-.46-.04-.92-.1-1.36a5.389 5.389 0 0 1-4.4 2.26 5.403 5.403 0 0 1-3.14-9.8c-.44-.06-.9-.1-1.36-.1z"></path></svg></button></div></div></div></nav><div class="container min-h-[80vh] mt-24 mx-auto px-12 lg:px-16 py-4 "><div class="flex justify-center"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="txt-color-primary text-center text-4xl font-bold pb-6">Education</h1><ul class="grid gap-8 mb-8"><li><div><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">McGill University</h5><h5 class="text-xl font-semibold">Sep. 2020 - Oct. 2022</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">Master of Arts in Music Technology (Thesis)</h6><h6 class="text-lg italic">Montreal, Quebec</h6></div></div><div class="txt-color-secondary"><ul class="list-style"><li><span>GPA: 4.0</span></li><li><span>Thesis: Music Emotion Recognition on Lyrics Using Natural Language Processing | Supervisor: Prof. Ichiro Fujinaga</span></li></ul></div></div></li><li><div><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">Communication University of China</h5><h5 class="text-xl font-semibold">Sep. 2016 - Jul. 2020</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">Bachelor of Engineering in Network Engineering</h6><h6 class="text-lg italic">Beijing, China</h6></div></div><div class="txt-color-secondary"><ul class="list-style"><li><span>Excellent Thesis: Research on Optical Music Notation Recognition Based on Convolutional Neural Network</span></li></ul></div></div></li></ul></div></div><div class="flex justify-center mt-6"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="w-full txt-color-primary text-center text-4xl font-bold pb-6">School Projects</h1><ul class="grid gap-8"><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">MUMT 621 Multimodal Music Emotion Recognition Using Convolutional Neural Network</h5><div class="flex items-center mb-2"><a target="_blank" href="https://github.com/yinanazhou/Multimodal-Music-Emotion"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="txt-color-primary transition-transform hover:scale-110" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="txt-color-secondary"><p>This project explores the performance of multimodal learning on Music Emotion Recognition. Unimodal and bimodal methods on audio and lyrical features were built and compared. Both middle fusion and late fusion were applied for bimodal methods. This result demonstrates that the combination of two feature domains can improve the MER performance.</p></div></div></div></li><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">MUMT 501 Dereverberation on Music Signals</h5><div class="flex items-center mb-2"><a target="_blank" href="https://github.com/yinanazhou/Dereverberation"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="txt-color-primary transition-transform hover:scale-110" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="txt-color-secondary"><p>This project implements a block-based dereverberation algorithm. The hyperparameter settings are explored on a singing voice recording. Moreover, the algorithm is also implemented on a short clip of a symphonic music piece by Mozart. It is found that this algorithm has limited effect on signals with high reverberation. The hyperparameter setting for high reverberation extraction is also discussed.</p></div></div></div></li><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">MUMT 618 Realization and Comparison on Ukulele Sound Synthesis Models</h5><div class="flex items-center mb-2"><a target="_blank" href="https://github.com/yinanazhou/ukulele-sound-synthesis"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="txt-color-primary transition-transform hover:scale-110" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="txt-color-secondary"><p>This project implements both Karplus-Strong algorithm and digital waveguide model to synthesize ukulele sound. A system is then built to play MIDI files with the resulting sound of two models.</p></div></div></div></li><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">MUMT 605 Cepstral Analysis of Audio Signals</h5><div class="flex items-center mb-2"><a target="_blank" href="https://github.com/yinanazhou/cepstral-analysis"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="txt-color-primary transition-transform hover:scale-110" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="txt-color-secondary"><p>This project introduces the basic concepts of cepstrum and cepstrogram. Their implementations in pitch estimation, spectral envelope estimation, and audio feature extraction are also covered.</p></div></div></div></li><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">College Students Innovation and Entrepreneurship Training Program in Automatic Classification of Music Emotion Based on Machine Learning</h5><div class="txt-color-secondary"><ul class="list-style"><li>Scraped MIDI files on YouTube with music emotion labels.</li><li>Extracted MFCC, chords, and other features from music fragments.</li><li>Trained deep neural network models to get the output value; calculated error and updated model parameters to reduce error.</li></ul></div></div></div></li><li><div><div class="rounded-b-xl py-2 px-4"><h5 class="txt-color-primary text-xl font-semibold mb-2">Scientific Research Camp on School Bullying Detection Based on Pattern Recognition at Harbin Institute of Technology</h5><div class="txt-color-secondary"><ul class="list-style"><li>Preprocessed motion and speech data using techniques including wavelet filtering, pre-emphasis, windowing, and Fourier transform.</li><li>Performed feature extraction, filtering, and dimensionality reduction on motion and speech data using quartile box charts and PCA algorithms.</li><li>Classified data using KNN, GMM, and decision trees.</li></ul></div></div></div></li></ul></div></div><div class="flex justify-center mt-6"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="w-full txt-color-primary text-center text-4xl font-bold pb-6">Publications</h1><div class="items-center px-3"><ul class="grid gap-8 list-style txt-color-secondary"><li><span>Pang, Long, Ao Li, Yinan Zhou, Chen Yang, Yizhuang Xie, and He Chen. “Word length Optimization Method for Radix-2 k Fixed-Point Pipeline FFT Processors.” In 2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP), pp. 1-4. IEEE, 2019.</span></li><li><span>Zhao, Wei, Yinan Zhou, Yun Tie, and Yushu Zhao. “Recurrent Neural Network for MIDI Music Emotion Classification.” In 2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), pp. 2596-2600. IEEE, 2018.</span></li><li><span>Zhao, Wei, Wang, Lihao, Huang, Jingwen, Zhou, Yinan. “Music Emotion Recognition Based on Feed-Forward Neural Network.” Communication University of China Journal – Natural Science Edition. Vol. 25, No. 4 (2018): 1-5. Grade: 98.88%, issue date: 2021.05</span></li></ul></div></div></div><div class="flex justify-center mt-6"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="w-full txt-color-primary text-center text-4xl font-bold pb-6">Awards &amp; Scholarships</h1><div class="items-center px-3"><ul class="grid gap-8 txt-color-secondary"><li><ul class="list-style"><li><span class="font-bold">Schulich School of Music, McGill University, Montreal, Canada</span><ul class="list-style"><li class="list-[circle] pl-6">2020 Graduate Excellence Fellowship Awards</li></ul></li></ul></li><li><ul class="list-style"><li><span class="font-bold">Communication University of China, Beijing, China</span><ul class="list-style"><li class="list-[circle] pl-6">2018 First-Class Scholarship, awarded for ranking 2nd in the class</li><li class="list-[circle] pl-6">2018 Individual Scholarship for Academic Improvement, awarded by the Information Engineering School, Faculty of Science and Technology</li><li class="list-[circle] pl-6">2018 First Prize, 3rd Annual Science and Technology Innovation Competition Robot Match</li><li class="list-[circle] pl-6">2017 Third-Class Scholarship, awarded for ranking 6th in the class</li><li class="list-[circle] pl-6">2017 Three-Merits Student Award</li></ul></li></ul></li><li><ul class="list-style"><li><span class="font-bold">Beijing College Students Sound Trend Meter “College Broadcast Unit” Genre Broadcast, Beijing, China</span><ul class="list-style"><li class="list-[circle] pl-6">2018 Excellent Works Award</li><li class="list-[circle] pl-6">2017 Second Prize</li></ul></li></ul></li><li><ul class="list-style"><li><span class="font-bold">CTV Guangxin Innovation Scholarship, Beijing, China</span><ul class="list-style"><li class="list-[circle] pl-6">2018 Excellence in Innovation Award for paper “Recurrent neural network for MIDI music emotion classification”</li></ul></li></ul></li><li><ul class="list-style"><li><span class="font-bold">Gaojiao Cup National College Students Mathematical Modeling Contest, Beijing, China</span><ul class="list-style"><li class="list-[circle] pl-6">2018 Group A Second Prize</li><li class="list-[circle] pl-6">2017 Group A Successful Participation Award</li></ul></li></ul></li><li><ul class="list-style"><li><span class="font-bold">Dance Robot Competition and College Student Robot Competition</span><ul class="list-style"><li class="list-[circle] pl-6">2017 Group Second Prize, Beijing, China</li><li class="list-[circle] pl-6">2017 Group Second Prize, North China</li></ul></li></ul></li></ul></div></div></div><div class="flex justify-center mt-6"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="w-full txt-color-primary text-center text-4xl font-bold pb-6">Certificates</h1><div class="items-center px-6"><ul class="grid gap-8 txt-color-secondary list-style"><li><a target="_blank" class="link" href="https://www.coursera.org/account/accomplishments/certificate/EAETXSBSAU62">Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</a><br/><span>Grade: 100%, issue date: 2019.08</span></li><li><a target="_blank" class="link" href="https://www.coursera.org/account/accomplishments/certificate/LNQVQFYJQR4U">Natural Language Processing in TensorFlow</a><br/><span>Grade: 100%, issue date: 2019.09</span></li><li><a target="_blank" class="link" href="https://www.coursera.org/account/accomplishments/certificate/KXUY2SSLN9ZT">Python Basics</a><br/><span>Grade: 100%, issue date: 2020.03</span></li><li><a target="_blank" class="link" href="https://www.coursera.org/account/accomplishments/certificate/NCVCUCWZ7WFF">Getting Started in Google Analytics</a><br/><span>Grade: 100%, issue date: 2021.03</span></li><li><a target="_blank" class="link" href="https://www.coursera.org/account/accomplishments/verify/RUVHVZNKHKVQ?utm_source=link&amp;utm_medium=certificate&amp;utm_content=cert_image&amp;utm_campaign=sharing_cta&amp;utm_product=course">Fundamentals of Music Theory</a><br/><span></span></li></ul></div></div></div><div class="flex justify-center mt-6"><div class="rounded-xl w-full mt-3 card-bg py-6 px-6 shadow-md shadow-neutral-500/30" style="opacity:0;transform:translateY(50px)"><h1 class="w-full txt-color-primary text-center text-4xl font-bold pb-6">Volunteer</h1><div class="items-center px-3"><ul class="grid gap-8 list-style txt-color-secondary"><div class=""><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">Manager of Overseas Internship Project Department</h5><h5 class="text-xl font-semibold">Sep. 2017 - Dec. 2017</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">AIESEC in CUC</h6><h6 class="text-lg italic">Beijing, China</h6></div></div><div class="txt-color-secondary text-justify"><ul class="list-style"><li><span>Led team members to plan promotional flyers and literature, as well as a new media campaign to promote overseas internships.</span></li><li><span>Assisted applicants in contacting overseas branches and applying for relevant visas.</span></li><li><span>Planned AIESEC in CUC (Communication University of China) gatherings, including poster design, invitation design and mailing, and party favors.</span></li></ul></div></div><div class=""><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">Global Volunteer</h5><h5 class="text-xl font-semibold">Aug. 2017 - Sep. 2017</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">AIESEC in AAST in Cairo</h6><h6 class="text-lg italic">Cairo, Egypt</h6></div></div><div class="txt-color-secondary text-justify"><ul class="list-style"><li><span>Promoted tourism and economic development in Egypt on social media platforms with the aim of reducing prejudices against Egypt.</span></li><li><span>Joined with 20 volunteers from multiple countries to visit ten cities in Egypt.</span></li><li><span>Researched Egyptian life, culture, religion, and history.</span></li></ul></div></div><div class=""><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">Manager of Talent Development Department</h5><h5 class="text-xl font-semibold">Jan. 2017 - Sep. 2017</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">AIESEC in CUC</h6><h6 class="text-lg italic">Beijing, China</h6></div></div><div class="txt-color-secondary text-justify"><ul class="list-style"><li><span>Responsible for the new recruits for Spring and Autumn 2017, coordinated social media campaigns, poster design, and marketing copy to promote AIESEC.</span></li><li><span>Performed market research on potential volunteers, candidate consultation, and interviewing.</span></li><li><span>Designed performance evaluation criteria for team members.</span></li></ul></div></div><div class=""><div class="header flex flex-col mb-4"><div class="first-line flex flex-col lg:flex-row justify-between txt-color-primary"><h5 class="text-xl font-semibold">Member of International Youth Immigration Exchange Department</h5><h5 class="text-xl font-semibold">Jun. 2016 - Dec. 2016</h5></div><div class="second-line flex flex-col lg:flex-row justify-between txt-color-secondary"><h6 class="text-lg italic">AIESEC in CUC</h6><h6 class="text-lg italic">Beijing, China</h6></div></div><div class="txt-color-secondary text-justify"><ul class="list-style"><li><span>Recruited 7 new members to the AIESEC local volunteer team.</span></li><li><span>Planned the Impression Beijing public welfare program to protect traditional Chinese culture by interviewing artists, making a video, and making traditional artwork with foreign volunteers.</span></li></ul></div></div></ul></div></div></div></div><footer class="footer mt-10 flex justify-center border z-10 bg-neutral-100 dark:bg-neutral-900 border-neutral-300 border-l-transparent border-r-transparent dark:border-[#33353F] dark:border-l-transparent dark:border-r-transparent"><div class="container px-12 py-4 flex justify-between items-center "><div href="/" class="text-2xl lg:text-4xl text-neutral-900 dark:text-neutral-100 __className_64bce7">YINAN</div><p class="font-mono text-xs md:text-sm text-neutral-600 dark:text-neutral-300">— <!-- -->2024-12
<!-- --> —</p><p class="text-xs md:text-base text-neutral-900 dark:text-neutral-100">All rights reserved.</p></div></footer></main><script src="/_next/static/chunks/webpack-471744ee643a0223.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"5:\"$Sreact.fragment\"\n6:I[5244,[],\"\"]\n7:I[3866,[],\"\"]\n8:I[840,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\n9:I[178,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\na:I[124,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\nb:I[1368,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\nc:I[2349,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\nd:I[5103,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\ne:I[1465,[\"479\",\"static/chunks/795d4814-4cf137b2b18c6ba6.js\",\"711\",\"static/chunks/8e1d74a4-37a392b9a35a4a16.js\",\"760\",\"static/chunks/f7333993-1ff95e909beea13f.js\",\"910\",\"static/chunks/910-a97ce0c10fadb44e.js\",\"32\",\"static/chunks/app/academic/page-22f8083129f4684b.js\"],\"default\"]\nf:I[6213,[],\"OutletBoundary\"]\n11:I[621"])</script><script>self.__next_f.push([1,"3,[],\"MetadataBoundary\"]\n13:I[6213,[],\"ViewportBoundary\"]\n15:I[4835,[],\"\"]\n1:HL[\"/_next/static/media/c4250770ab8708b6-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/bd9e0cabbc41a073.css\",\"style\"]\n3:HL[\"/_next/static/media/f7db1e3b5f03d91f-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/css/2799974cb986be26.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"EN1cPzKVDG6CCnMbaJXBL\",\"p\":\"\",\"c\":[\"\",\"academic\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"academic\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$5\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/bd9e0cabbc41a073.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_48ea4f\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]}]]}],{\"children\":[\"academic\",[\"$\",\"$5\",\"c\",{\"children\":[null,[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"academic\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$5\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"flex min-h-screen flex-col bg-neutral-100 dark:bg-neutral-900\",\"children\":[[\"$\",\"$L8\",null,{\"page\":\"Academic\"}],[\"$\",\"div\",null,{\"className\":\"container min-h-[80vh] mt-24 mx-auto px-12 lg:px-16 py-4 \",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"$La\",null,{}],[\"$\",\"$Lb\",null,{}],[\"$\",\"$Lc\",null,{}],[\"$\",\"$Ld\",null,{}],[\"$\",\"$Le\",null,{}]]}],[\"$\",\"footer\",null,{\"className\":\"footer mt-10 flex justify-center border z-10 bg-neutral-100 dark:bg-neutral-900 border-neutral-300 border-l-transparent border-r-transparent dark:border-[#33353F] dark:border-l-transparent dark:border-r-transparent\",\"children\":[\"$\",\"div\",null,{\"className\":\"container px-12 py-4 flex justify-between items-center \",\"children\":[[\"$\",\"div\",null,{\"href\":\"/\",\"className\":\"text-2xl lg:text-4xl text-neutral-900 dark:text-neutral-100 __className_64bce7\",\"children\":\"YINAN\"}],[\"$\",\"p\",null,{\"className\":\"font-mono text-xs md:text-sm text-neutral-600 dark:text-neutral-300\",\"children\":[\"— \",\"2024-12\\n\",\" —\"]}],[\"$\",\"p\",null,{\"className\":\"text-xs md:text-base text-neutral-900 dark:text-neutral-100\",\"children\":\"All rights reserved.\"}]]}]}]]}],[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2799974cb986be26.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}]]}],{},null]},null]},null],[\"$\",\"$5\",\"h\",{\"children\":[null,[\"$\",\"$5\",\"aoYNgtpaw7idpn9gdJlkF\",{\"children\":[[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]]}]]}]]],\"m\":\"$undefined\",\"G\":[\"$15\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n12:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Yinan Zhou\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Personal Website\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"10:null\n"])</script></body></html>